---
title: 'STAT 420: Final Project'
author: "Chenhan Xu (chenhan2)"
date: 'Friday, May 3'
output:
  html_document:
    theme: readable
    toc: yes
---

### Abstract

In this report, we will try to fit a proper linear regression model to predict the `Disease.Severity` in the `disease` dataset using other variables. We will first check the **multicollinearity** of the dataset and try to reduce the predictors. Then we will fit the full **additive** linear models and try to interpret and diagnose them with different methods. As these two model do not fit the data well, we try to use **response transformation** to find a better one. For each family of models, we use **Bayesian Information Criterion (BIC)** to do the variable selection. We prefer BIC here instead of AIC because with large sample data size, BIC tends to find a smaller model that can be more interpretable. For each model we find using BIC, we will use **Cook's Distance** to remove the influencial unusual observation. Test of model assumption will be given to each of the models. Finally, this report will arrive at a proper model for the dataset.

### Setup of the project

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
```

Import the `disease` dataset and the packages that contain the necessary functions for this project. 

```{r, warning = FALSE, message = FALSE}
library(faraway)
library(lmtest)
library(MASS)
library(leaps)
```

```{r}
disease = read.csv("Disease Data.csv")
```

Define some of the functions that we may need for convenience.

```{r}
fitted_vs_resid = function(model) {
  plot(fitted(model), resid(model),
       col = "grey", pch = 20,
       xlab = "Fitted Value",
       ylab = "Residual",
       main = "Fitted Value versus Residual")
  abline(h = 0, lwd = 3, col = "dodgerblue")
}
qqplot = function(model) {
  qqnorm(resid(model), col = "grey", lwd = 3)
  qqline(resid(model), col = "dodgerblue", cex = 1.5, pch = 20)
}
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
```

### Summary Statistics and Data Visualization

First, we look at the variales of the data frame.

```{r}
str(disease)
```

We noticed that `X` variable is the index of observations. In this case, the data of different patients is independent with the index, so we remove `X` from the data frame.

```{r}
disease = subset(disease, select = - X)
```

```{r}
hist(disease$Disease.Severity, breaks = 50,
     border = "dodgerblue")
```

The histogram shows the distribution of `Disease.Severity` is right skewed.

```{r}
boxplot(disease$Disease.Severity, main = "Boxplot of Disease Severity")
```

The boxplot shows that the median of `Disease.Severity` is slightly over 2, but there are a lot of outliers in the dataset.

The table below shows some important statistics of `Disease.Severity`.

```{r}
data_analysis = data.frame(
  "Measure" = c("Mean", "Median", "Variance", "Standard Deviation", "Max", "Min"),
  "Result" = c(mean(disease$Disease.Severity), median(disease$Disease.Severity), var(disease$Disease.Severity), sd(disease$Disease.Severity), max(disease$Disease.Severity), min(disease$Disease.Severity)))
knitr::kable(data_analysis)
```

Before we start fitting the model, we check if there is collinearity in between variables to see if we can reduce some variables.

We test the mulitcollinearity using **variance inflation factor (VIF)**.

```{r}
vif(disease)
vif(disease)[which(vif(disease) > 5)]
```

We notice that predictors `F2R` and `PLEKHM1` have **vif** greater than 5. Therefore, we look at variable added plots and partial correlation coefficients for these two predictors.

First, we focus on `F2R`.

```{r}
fit_full_without_F2R = lm(Disease.Severity ~ . - F2R, data = disease)
fit_F2R = lm(F2R ~ . - Disease.Severity, data = disease)
```
```{r}
cor(resid(fit_full_without_F2R), resid(fit_F2R))
```
```{r}
plot(resid(fit_full_without_F2R) ~ resid(fit_F2R),
     col = "dodgerblue", pch = 20,
     xlab = "Residuals, Added Predictor", 
     ylab = "Residuals, Original Model")
abline(h = 0, lty = 2)
abline(v = 0, lty = 2)
abline(lm(resid(fit_full_without_F2R) ~ resid(fit_F2R)),
       col = "darkorange", lwd = 2)
```

Next, we look at `PLEKHM1`.

```{r}
fit_full_without_PLEKHM1 = lm(Disease.Severity ~ . - PLEKHM1, data = disease)
fit_PLEKHM1 = lm(PLEKHM1 ~ . - Disease.Severity, data = disease)
```
```{r}
cor(resid(fit_full_without_PLEKHM1), resid(fit_PLEKHM1))
```
```{r}
plot(resid(fit_full_without_PLEKHM1) ~ resid(fit_PLEKHM1),
     col = "dodgerblue", pch = 20,
     xlab = "Residuals, Added Predictor", 
     ylab = "Residuals, Original Model")
abline(h = 0, lty = 2)
abline(v = 0, lty = 2)
abline(lm(resid(fit_full_without_PLEKHM1) ~ resid(fit_PLEKHM1)),
       col = "darkorange", lwd = 2)
```

The partial correlation coefficients of both predictors are unignorable. The variable added plots also show that the variations of `F2R` and `PLEKHM1` have correlation with other predictors. This means that their variations are unexplained by other predictors. Hence, we prefer to keep these two predictors in the model.

### Full Model

We try to fit the full additive model.

```{r}
fit_full_add = lm(Disease.Severity ~ ., data = disease)
```

```{r}
summary(fit_full_add)
```

The full additive model contains 21 coefficients. The F-test shows that the model is significant. However, the single variable t-tests show that many of the predictors in the full additive model are insignificant. 

Next, we check if the model violate some of the assumptions.

```{r}
fitted_vs_resid(fit_full_add)
qqplot(fit_full_add)
```

We notice that there are some unusual data points in the plot, so we use the **Cook's Distance** to identify and remove them.

```{r}
n = nrow(disease)
p = length(coef(fit_full_add))
```

```{r}
cook_full_add = cooks.distance(fit_full_add)
outlier_full_add = which(cook_full_add > 4 / n)
cook_full_add[outlier_full_add]
```

```{r}
fit_full_add = lm(Disease.Severity ~ ., data = disease[-outlier_full_add,])
```

Now, we removed the unusual observations and let's look back intto the two plots. 

```{r}
fitted_vs_resid(fit_full_add)
qqplot(fit_full_add)
```

Through the plots, we clearly notice that the **Linear Assumption**, **Constant Variance Assumption** and **Normality Assumptions** are all violated. In this way, this model is terrible.

We use **BIC** to try to find a better smaller additive model.

```{r}
fit_bic_add = step(fit_full_add, direction = "backward", trace = 0, k = log(n))
``` 

```{r}
fitted_vs_resid(fit_bic_add)
qqplot(fit_bic_add)
```

However, the plots tells that the smaller additive model is again terrible. This matches our expectation since we know that simply removing predictors may not help dealing with the **linear**, **constant variance** and **normality** assumptions.

In the next few sections, we will perform response transformation to find a better model.

### Log mode

The Fitted Value vs Residual plot shown above suggests that a **log-transformation** on response may be helpful.

```{r}
fit_full_log_add = lm(log(Disease.Severity) ~ ., data = disease)
```

We fit a full log model and then use **BIC** to find a proper smaller model.

```{r}
fit_bic_log_add = step(fit_full_log_add, direction = "backward", k = log(n), trace = 0)
```

```{r}
cook_bic_log = cooks.distance(fit_bic_log_add)
outlier_log_add = which(cook_bic_log > 4 / n)
cook_bic_log[outlier_full_add]
```

The **Cook's Distance** tells that there are some influential observations in the dataset, so we remove them to get a better estimation.

```{r}
fit_full_log_add = lm(log(Disease.Severity) ~ ., data = disease[-outlier_log_add, ])
```

```{r}
fit_bic_log_add = step(fit_full_log_add, direction = "backward", trace = 0, k = log(n))
```

```{r}
summary(fit_bic_log_add)
```

The backward search suggests a model with 10 predictors as above. Single variable t-tests show that all the predictors are significant. The F-test shows that the model is significant.

Now, let's look at the model assumptions.

```{r}
fitted_vs_resid(fit_bic_log_add)
qqplot(fit_bic_log_add)
```

```{r}
bptest(fit_bic_log_add)
```

```{r}
shapiro.test(resid(fit_bic_log_add))
```

The Fitted Value vs Residual plot and Q-Q plot look good. Furthermore, the **Breusch-Pagan Test** and **Shapiro-Wilk Test** both have a large p-value. Therefore, the model assumptions are not violated. This model is a good one.

In the following section, we will use **Boxcox Method** to find if there is a better response transformation.

### Boxcox model


```{r}
boxcox(fit_full_add, plotit = TRUE, lambda = seq(-0.5, 0, by = 0.05))
```

The Boxcox plot suggests that $\lambda \in [-0.4,-0.1]$ can be a good $\lambda$ for transformation. We choose $\lambda = -0.25$ as it has relative high log-Likelihood.

Therefore, the transformation of the response is $y^{-0.25} - 1 \over -0.25$.

Fit a linear model based on this response transformation and use **BIC** to find a proper smaller model.

```{r}
fit_boxcox = lm(((Disease.Severity^(-0.25) - 1) / (-0.25)) ~ ., data = disease)
```

```{r}
fit_bic_boxcox = step(fit_boxcox, direction = "backward", trace = 0, k = log(n))
```

Again, us **Cook's Distance** to identify and remove the influential unusual observations. Rebuild the model based on the modified dataset.

```{r}
cook_boxcox = cooks.distance(fit_bic_boxcox)
outlier_boxcox = which(cook_boxcox > 4 / n)
```

```{r}
fit_boxcox = lm(((Disease.Severity^(-0.25) - 1) / (-0.25)) ~ ., data = disease[-outlier_boxcox,])
```

```{r}
fit_bic_boxcox = step(fit_boxcox, direction = "backward", trace = 0, k = log(n))
```

Summary the new model.

```{r}
summary(fit_bic_boxcox)
```

The new model has 10 predictors all of which are significant in the model. The $R^2$ is 0.757 in the model. The statistics of the model look pretty good.

Then do the test on the model assumptions.

```{r}
fitted_vs_resid(fit_bic_boxcox)
qqplot(fit_bic_boxcox)
```

```{r}
bptest(fit_bic_boxcox)
shapiro.test(resid(fit_bic_boxcox))
```

The Fitted Value vs Residual plot looks good, the **linear assumption** and **constant variance assumption** are not violated. The Q-Q plot also looks good, the data points fall along the normal line. **Normality assumption** is also not violated.

Furthermore, the Breusch-Pagan test and Shapiro-Wilk test both have large p-value. None of the assumptions is violated.

The $R^2$ of the model suggests that 75.7% of the data can be explained by this model. 

**Conclusion**


