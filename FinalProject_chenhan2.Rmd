---
title: 'STAT 420: Final Project'
author: "Chenhan Xu (chenhan2)"
date: 'Friday, May 3'
output:
  html_document:
    theme: readable
    toc: yes
  pdf_document:
    toc: yes
---

**Abstract**

In this report, we will try to fit a proper linear regression model to predict the `Disease.Severity` in the `disease` dataset using other variables. We will first check the **multicollinearity** of the dataset and try to reduce the predictors. Then we will fit the full **additive** linear models and try to interpret and diagnose them with different methods. As these two model do not fit the data well, we try to use **response transformation** to find a better one. For each family of models, we use **Bayesian Information Criterion (BIC)** to do the variable selection. We prefer BIC here instead of AIC because with large sample data size, BIC tends to find a smaller model that can be more interpretable. For each model we find using BIC, we will use **Cook's Distance** to remove the influencial unusual observation. Test of model assumption will be given to each of the models. Finally, this report will arrive at a proper model for the dataset.

**Setup of the project**

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
```

Import the `disease` dataset and the packages that contain the necessary functions for this project. 

```{r, warning = FALSE, message = FALSE}
disease = read.csv("Disease Data.csv")
library(lmtest)
library(faraway)
library(MASS)
library(leaps)
```

Define some of the functions that we may need for convenience.

```{r}
fitted_vs_resid = function(model) {
  plot(fitted(model), resid(model),
       col = "grey", pch = 20,
       xlab = "Fitted Value",
       ylab = "Residual",
       main = "Fitted Value versus Residual")
  abline(h = 0, lwd = 3, col = "dodgerblue")
}
qqplot = function(model) {
  qqnorm(resid(model), col = "grey", lwd = 3)
  qqline(resid(model), col = "dodgerblue", cex = 1.5, pch = 20)
}
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
```

**Summary Statistics and Data Visualization**

First, we look at the variales of the data frame.

```{r}
str(disease)
```

We noticed that `X` variable is the index of observations, so we remove it from the data frame.

```{r}
disease = subset(disease, select = - X)
```

Before we start fitting the model, we check if there is collinearity in between variables to see if we can reduce some variables.

The following table shows the paired-correlationship, with `TRUE` meaning strong correlation and `FALSE` meaning no strong correlation.

```{r, eval = FALSE}
correlation_within = cor(disease)
abs(correlation_within) > 0.9
```

The paired correlation coefficients show no strong paired correlations between variables.

We go further to test the mulitcollinearity using **variance inflation factor (VIF)**.

```{r}
vif(disease)
vif(disease)[which(vif(disease) > 5)]
```

We notice that predictors `F2R` and `PLEKHM1` have **vif** greater than 5. Therefore, we look at variable added plots and partial correlation coefficients for these two predictors.

First, we focus on `F2R`.

```{r}
fit_full_without_F2R = lm(Disease.Severity ~ . - F2R, data = disease)
fit_F2R = lm(F2R ~ . - Disease.Severity, data = disease)
```
```{r}
cor(resid(fit_full_without_F2R), resid(fit_F2R))
```
```{r}
plot(resid(fit_full_without_F2R) ~ resid(fit_F2R),
     col = "dodgerblue", pch = 20,
     xlab = "Residuals, Added Predictor", 
     ylab = "Residuals, Original Model")
abline(h = 0, lty = 2)
abline(v = 0, lty = 2)
abline(lm(resid(fit_full_without_F2R) ~ resid(fit_F2R)),
       col = "darkorange", lwd = 2)
```

Next, we look at `PLEKHM1`.

```{r}
fit_full_without_PLEKHM1 = lm(Disease.Severity ~ . - PLEKHM1, data = disease)
fit_PLEKHM1 = lm(PLEKHM1 ~ . - Disease.Severity, data = disease)
```
```{r}
cor(resid(fit_full_without_PLEKHM1), resid(fit_PLEKHM1))
```
```{r}
plot(resid(fit_full_without_PLEKHM1) ~ resid(fit_PLEKHM1),
     col = "dodgerblue", pch = 20,
     xlab = "Residuals, Added Predictor", 
     ylab = "Residuals, Original Model")
abline(h = 0, lty = 2)
abline(v = 0, lty = 2)
abline(lm(resid(fit_full_without_PLEKHM1) ~ resid(fit_PLEKHM1)),
       col = "darkorange", lwd = 2)
```

The partial correlation coefficients of both predictors are unignorable. The variable added plots also show that the variations of `F2R` and `PLEKHM1` have correlation with other predictors. This means that their variations are explained by other predictors. Hence, we prefer to keep these two predictors in the model.

**Fit the Full Model**

We try to fit the full additive model.

```{r}
fit_full_add = lm(Disease.Severity ~ ., data = disease)
```

```{r}
summary(fit_full_add)
```

The full additive model contains 21 coefficients. The F-test shows that the model is significant. However, the single variable t-tests show that many of the predictors in the full additive model are insignificant. 

Next, we check if the model violate some of the assumptions.

```{r}
fitted_vs_resid(fit_full_add)
qqplot(fit_full_add)
```

We notice that there are some unusual data points in the plot, so we use the **Cook's Distance** to identify and remove them.

```{r}
n = nrow(disease)
p = length(coef(fit_full_add))
```

```{r}
cook_full_add = cooks.distance(fit_full_add)
outlier_full_add = which(cook_full_add > 4 / n)
cook_full_add[outlier_full_add]
```

```{r}
fit_full_add = lm(Disease.Severity ~ ., data = disease[-outlier_full_add,])
```

Now, we removed the unusual observations and let's look back intto the two plots. 

```{r}
fitted_vs_resid(fit_full_add)
qqplot(fit_full_add)
```

Through the plots, we clearly notice that the **Linear Assumption**, **Constant Variance Assumption** and **Normality Assumptions** are all violated. In this way, this model is terrible.

We use **BIC** to try to find a better smaller additive model.

```{r}
fit_bic_add = step(fit_full_add, direction = "backward", trace = 0, k = log(n))
``` 

```{r}
fitted_vs_resid(fit_bic_add)
qqplot(fit_bic_add)
```

However, the plots tells that the smaller additive model is again terrible. This matches our expectation since we know that simply removing predictors may not help dealing with the **linear**, **constant variance** and **normality** assumptions.

In the next few sections, we will perform response transformation to find a better model.

**Log model**

The Fitted Value vs Residual plot shown above suggests that a **log-transformation** on response may be helpful.

```{r}
fit_full_log_add = lm(log(Disease.Severity) ~ ., data = disease)
```

We fit a full log model and then use **BIC** to find a proper smaller model.

```{r}
fit_bic_log_add = step(fit_full_log_add, direction = "backward", k = log(n), trace = 0)
```

```{r}
cook_bic_log = cooks.distance(fit_bic_log_add)
outlier_log_add = which(cook_bic_log > 4 / n)
cook_bic_log[outlier_full_add]
```

The **Cook's Distance** tells that there are some influential observations in the dataset, so we remove them to get a better estimation.

```{r}
fit_full_log_add = lm(log(Disease.Severity) ~ ., data = disease[-outlier_log_add, ])
```

```{r}
fit_bic_log_add = step(fit_full_log_add, direction = "backward", trace = 0, k = log(n))
```

```{r}
summary(fit_bic_log_add)
```

The backward search suggests a model with 10 predictors as above. Single variable t-tests show that all the predictors are significant. The F-test shows that the model is significant.

Now, let's look at the model assumptions.

```{r}
fitted_vs_resid(fit_bic_log_add)
qqplot(fit_bic_log_add)
```

```{r}
bptest(fit_bic_log_add)
```

```{r}
shapiro.test(resid(fit_bic_log_add))
```

The Fitted Value vs Residual plot and Q-Q plot look good. Furthermore, the **Breusch-Pagan Test** and **Shapiro-Wilk Test** both have a large p-value. Therefore, the model assumptions are not violated. This model is a good one.

**Log Interaction**

```{r, eval = FALSE}
fit_full_log_int = lm(log(Disease.Severity) ~ . ^ 2, data = disease[-outlier_log_add, ])
```

```{r, eval = FALSE}
fit_bic_log_int = step(fit_full_log_int, direction = "backward", k = log(n), trace = 0)
```

```{r, eval = FALSE}
summary(fit_bic_log_int)
```

```{r, eval = FALSE}
fitted_vs_resid(fit_bic_log_int)
qqplot(fit_bic_log_int)
```

```{r, eval = FALSE}
bptest(fit_bic_log_int)
shapiro.test(resid(fit_bic_log_int))
```

```{r, eval = FALSE}
anova(fit_bic_log_add, fit_bic_log_int)
```

**Boxcox model**



```{r}
boxcox(fit_full_add, plotit = TRUE, lambda = seq(-0.5, 0, by = 0.05))
```

```{r}
fit_boxcox = lm(((Disease.Severity^(-0.25) - 1) / (-0.25)) ~ ., data = disease)
```

```{r}
fit_bic_boxcox = step(fit_boxcox, direction = "backward", trace = 0, k = log(n))
```

```{r}
summary(fit_bic_boxcox)
```

```{r}
cook_boxcox = cooks.distance(fit_bic_boxcox)
outlier_boxcox = which(cook_boxcox > 4 / n)
cook_boxcox[outlier_boxcox]
```
```{r}
fit_boxcox = lm(((Disease.Severity^(-0.25) - 1) / (-0.25)) ~ ., data = disease[-outlier_boxcox,])
```

```{r}
fit_bic_boxcox = step(fit_boxcox, direction = "backward", trace = 0, k = log(n))
```


```{r}
summary(fit_bic_boxcox)
```

```{r}
fitted_vs_resid(fit_bic_boxcox)
qqplot(fit_bic_boxcox)
```

```{r}
bptest(fit_bic_boxcox)
shapiro.test(resid(fit_bic_boxcox))
```


```{r}

all_boxcox_models = summary(regsubsets(((Disease.Severity^(-0.25) - 1) / (-0.25)) ~ ., data = disease))
all_boxcox_models$which
```

```{r}
fit_boxcox_small = lm(((Disease.Severity^(-0.25) - 1) / (-0.25)) ~ PCDH12 + DLG5 + SHISA5 + AF161342 + F2R + PLEKHM1 + PPAN + LOC440104, data = disease[-outlier_log_add,])
```

```{r, eval = FALSE}
anova(fit_boxcox_small, fit_boxcox)
```

